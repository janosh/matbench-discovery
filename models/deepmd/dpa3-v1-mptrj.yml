model_name: DPA3-v1-MPtrj
model_key: dpa3-v1-mptrj
model_version: v0.1 # 2025-01-10
matbench_discovery_version: 1.3.1
date_added: "2025-01-10"
date_published: "2025-01-10"
authors:
  - name: Duo Zhang
    affiliation: AI for Science Institute, Beijing
    orcid: https://orcid.org/0000-0001-9591-2659
  - name: Anyang Peng
    affiliation: AI for Science Institute, Beijing
    orcid: https://orcid.org/0000-0002-0630-2187
  - name: Chun Cai
    affiliation: AI for Science Institute, Beijing
    orcid: https://orcid.org/0000-0001-6242-0439
  - name: Linfeng Zhang
    affiliation: AI for Science Institute, Beijing; DP Technology
    email: linfeng.zhang.zlf@gmail.com
    corresponding: true
  - name: Han Wang
    affiliation: Laboratory of Computational Physics, Institute of Applied Physics and Computational Mathematics
    email: wang_han@iapcm.ac.cn
    corresponding: true
trained_by:
  - name: Duo Zhang
    affiliation: AI for Science Institute, Beijing
    orcid: https://orcid.org/0000-0001-9591-2659
repo: https://github.com/deepmodeling/deepmd-kit/tree/dpa3-alpha
url: https://github.com/deepmodeling/deepmd-kit/tree/dpa3-alpha
doi: https://github.com/deepmodeling/deepmd-kit/tree/dpa3-alpha # to be released soon
paper: https://github.com/deepmodeling/deepmd-kit/tree/dpa3-alpha # to be released soon
pr_url: https://github.com/janosh/matbench-discovery/pull/192
trained_for_benchmark: true

openness: OSOD
train_task: S2EFS
test_task: IS2RE-SR
targets: EFS_G
model_type: UIP
model_params: 3_374_647
n_estimators: 1

hyperparams:
  max_force: 0.05
  max_steps: 500
  ase_optimizer: FIRE
  n_layers: 16
  e_rcut: 6.0
  a_rcut: 4.0
  n_dim: 128
  e_dim: 64
  a_dim: 32
  optimizer: Adam
  round1:
    loss: MSE
    loss_weights:
      energy: 0.2 -> 20
      force: 100 -> 20
      virial: 0.02 -> 1
    initial_learning_rate: 0.001
    learning_rate_schedule: ExpLR - start_lr=0.001, decay_steps=5000, stop_lr=0.00001
    training_steps: 2000000
  round2:
    loss: Huber
    loss_weights:
      energy: 15
      force: 1
      virial: 2.5
    initial_learning_rate: 0.0002
    learning_rate_schedule: ExpLR - start_lr=0.0002, decay_steps=5000, stop_lr=0.00001
    training_steps: 2000000
  batch_size: 64 # 16 (gpus) * 4 (batch per gpu) = 64 (total batch size)
  epochs: 160 # round1 80 + round2 80

requirements:
  torch: 2.3.1
  torch-geometric: 2.5.2
  ase: 3.23.0
  pymatgen: 2024.6.10
  numpy: 1.26.4

training_set: [MPtrj]

notes:
  Description: |
    DPA3 is an advanced interatomic potential leveraging the message passing architecture, implemented within the DeePMD-kit framework, available at GitHub(https://github.com/deepmodeling/deepmd-kit/tree/dpa3-alpha).
    Designed as a large atomic model (LAM), DPA3 is tailored to integrate and simultaneously train on datasets from various disciplines, encompassing diverse chemical and materials systems across different research domains.
    Its model design ensures exceptional fitting accuracy and robust generalization both within and beyond the training domain.
    Furthermore, DPA3 maintains energy conservation and respects the physical symmetries of the potential energy surface, making it a dependable tool for a wide range of scientific applications.

metrics:
  phonons:
    kappa_103:
      Îº_SRME: 0.964
      pred_file: models/deepmd/dpa3-v1-mptrj/2025-01-10-kappa-103-FIRE-dist=0.01-fmax=1e-4-symprec=1e-5.json.gz
      pred_file_url: https://figshare.com/ndownloader/files/52134860
  geo_opt:
    pred_file: models/deepmd/dpa3-v1-mptrj/2025-01-10-wbm-geo-opt.json.gz
    pred_col: dp_structure
    pred_file_url: https://figshare.com/ndownloader/files/52134974
    symprec=1e-5:
      analysis_file: models/deepmd/dpa3-v1-mptrj/2025-01-10-wbm-geo-opt-symprec=1e-5.csv.gz
      analysis_file_url: https://figshare.com/ndownloader/files/52059431
  discovery:
    pred_file: models/deepmd/dpa3-v1-mptrj/2025-01-10-wbm-IS2RE.csv.gz
    pred_file_url: https://figshare.com/ndownloader/files/52057529
    pred_col: e_form_per_atom_dp
    full_test_set:
      F1: 0.757 # fraction
      DAF: 4.13 # dimensionless
      Precision: 0.709 # fraction
      Recall: 0.812 # fraction
      Accuracy: 0.911 # fraction
      TPR: 0.812 # fraction
      FPR: 0.069 # fraction
      TNR: 0.931 # fraction
      FNR: 0.188 # fraction
      TP: 35812.0 # count
      FP: 14718.0 # count
      TN: 198153.0 # count
      FN: 8280.0 # count
      MAE: 0.04 # eV/atom
      RMSE: 0.082 # eV/atom
      R2: 0.793 # dimensionless
      missing_preds: 14 # count
      missing_percent: 0.01% # fraction
    most_stable_10k:
      F1: 0.971 # fraction
      DAF: 6.174 # dimensionless
      Precision: 0.944 # fraction
      Recall: 1.0 # fraction
      Accuracy: 0.944 # fraction
      TPR: 1.0 # fraction
      FPR: 1.0 # fraction
      TNR: 0.0 # fraction
      FNR: 0.0 # fraction
      TP: 9438.0 # count
      FP: 562.0 # count
      TN: 0.0 # count
      FN: 0.0 # count
      MAE: 0.038 # eV/atom
      RMSE: 0.084 # eV/atom
      R2: 0.849 # dimensionless
      missing_preds: 0 # count
      missing_percent: 0.00% # fraction
    unique_prototypes:
      F1: 0.765 # fraction
      DAF: 4.654 # dimensionless
      Precision: 0.711 # fraction
      Recall: 0.828 # fraction
      Accuracy: 0.921 # fraction
      TPR: 0.828 # fraction
      FPR: 0.062 # fraction
      TNR: 0.938 # fraction
      FNR: 0.172 # fraction
      TP: 27630.0 # count
      FP: 11205.0 # count
      TN: 170909.0 # count
      FN: 5744.0 # count
      MAE: 0.042 # eV/atom
      RMSE: 0.083 # eV/atom
      R2: 0.798 # dimensionless
      missing_preds: 11 # count
      missing_percent: 0.01% # fraction
