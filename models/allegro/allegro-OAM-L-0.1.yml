model_name: Allegro-OAM-L # required (this must match the model's label which is the 3rd arg in the matbench_discovery.preds.Model enum)
model_key: allegro-OAM-L-0.1 # this should match the name of the YAML file and determines the URL /models/<model_key> on which details of the model are displayed on the website
model_version: '0.1'
date_added: '2025-09-08'
date_published: '2025-08-28'
authors:
  - name: Seán R. Kavanagh
    affiliation: Center for the Environment, Harvard University & MIR Group, Harvard University
    email: skavanagh@seas.harvard.edu
    orcid: https://orcid.org/0000-0003-4577-9647
    url: https://seankavanagh.com
    corresponding: true
  - name: Chuin Wei Tan
    affiliation: MIR Group, Harvard University
  - name: Albert Musaelian
    affiliation: MIR Group, Harvard University & Mirian Technologies
  - name: William C. Witt
    affiliation: MIR Group, Harvard University
  - name: Gabriel de Miranda Nascimento
    affiliation: MIR Group, Harvard University & MIT
  - name: Ulrik Unneberg
    affiliation: MIR Group, Harvard University & MIT
  - name: Marc L. Descoteaux
    affiliation: MIR Group, Harvard University
  - name: Boris Kozinsky
    affiliation: MIR Group, Harvard University
trained_by:
  - name: Seán R. Kavanagh
    affiliation: Center for the Environment, Harvard University & MIR Group, Harvard University
    email: skavanagh@seas.harvard.edu
    orcid: https://orcid.org/0000-0003-4577-9647
    url: https://seankavanagh.com
    corresponding: true

repo: https://github.com/mir-group/allegro
url: https://allegro.readthedocs.io/en/latest/
doi: https://doi.org/10.5281/zenodo.16980200
paper: https://arxiv.org/abs/2504.16068 # To be updated...
checkpoint_url: https://www.nequip.net/models/mir-group/Allegro-OAM-L:0.1
pr_url: https://github.com/janosh/matbench-discovery/pull/282

openness: OSOD # see `Open` enum in matbench_discovery/enums.py
train_task: S2EFS # see `Task` enum in matbench_discovery/enums.py
test_task: IS2RE-SR # see `Task` enum in matbench_discovery/enums.py
targets: EFS_G # see `Targets` enum in matbench_discovery/enums.py
model_type: UIP # see `ModelType` enum in matbench_discovery/enums.py
model_params: 9_700_000
trained_for_benchmark: true
n_estimators: 1

license:
  code: MIT
  code_url: https://github.com/mir-group/nequip/blob/main/LICENSE
  checkpoint: CC-BY-4.0
  checkpoint_url: https://creativecommons.org/licenses/by/4.0/legalcode

hyperparams:
  max_force: 0.05
  max_steps: 500
  ase_optimizer: GOQN # faster than FIRE with same results; see SI of https://doi.org/10.1088/2515-7655/ade916
  cell_filter: FrechetCellFilter
  optimizer: AdamW
  weight_decay: 1e-8
  graph_construction_radius: 7.0
  sph_harmonics_l_max: 3
  n_layers: 4
  n_features: 64
  parity: false
  zbl_potential: false
  allegro_mlp_depth: 2
  allegro_mlp_width: 1024
  tensor_path_channel_coupling: true
  polynomial_cutoff: 8
  n_radial_bessel_basis: 12
  loss: Huber - delta=0.01 for energy, delta=0.1 for stress, stratified delta (0.01, 0.007, 0.004, 0.001) for force
  loss_weights:
    energy: 1.0
    force: 5.0
    stress: 0.01
  batch_size: 480 # 12 (gpus) * 40 (batch per gpu) = 480 (total batch size)
  initial_learning_rate: 0.005
  gradient_clip_val: 1e-4
  learning_rate_schedule: ReduceLROnPlateau - factor=0.1, patience=10, min_lr=1e-6
  epochs: 15
  max_neighbors: .inf

training_cost:
  Nvidia H100 GPUs: { amount: 12, hours: 100, cost: 1200 }

requirements:
  torch: '2'
  nequip: 0.7.0 # >=0.14.0 recommended
  allegro: 0.5.0 # >=0.7.1 recommended

training_set: [OMat24, sAlex, MPtrj]

notes:
  Description: Large Allegro foundation potential; see <https://www.nequip.net/models/mir-group/Allegro-OAM-L:0.1> for details and <https://arxiv.org/abs/2504.16068> for model/training infrastructure.
  Steps: |
    Training performed by: (1) pre-training on OMat24; (2) fine-tuning on MPtrj+sAlex, with a reduced learning rate (1e-4), energy-loss-upweighting (1:1:0.01 instead of 1:5:0.01) and `StochasticWeightAveraging` (SWA).

metrics:
  phonons:
    kappa_103:
      pred_file: models/allegro/Allegro-OAM-L-0.1/Allegro-OAM-L-0.1-2025-08-26-kappa-103-FIRE-dist_0_05-fmax_0_0001-symprec_1e-05.json.gz
      pred_file_url: https://figshare.com/files/57576247
      κ_SRME: 0.3186
      κ_SRE: 0.1433
  geo_opt:
    pred_file: models/allegro/Allegro-OAM-L-0.1/Allegro-OAM-L-0.1-2025-08-26-wbm-IS2RE-GOQN.jsonl.gz
    pred_file_url: https://figshare.com/files/57731011
    struct_col: nequip_structure # same for NequIP/Allegro
    symprec=1e-2:
      rmsd: 0.0651 # unitless
      n_sym_ops_mae: 1.7418 # unitless
      symmetry_decrease: 0.0542 # fraction
      symmetry_match: 0.816 # fraction
      symmetry_increase: 0.1226 # fraction
      n_structures: 256963 # count
      analysis_file: models/allegro/Allegro-OAM-L-0.1/Allegro-OAM-L-0.1-2025-08-26-wbm-IS2RE-GOQN-symprec=1e-2-moyo=0.4.4.csv.gz
      analysis_file_url: https://figshare.com/files/57731044
    symprec=1e-5:
      rmsd: 0.0651 # unitless
      n_sym_ops_mae: 1.924 # unitless
      symmetry_decrease: 0.0753 # fraction
      symmetry_match: 0.7163 # fraction
      symmetry_increase: 0.2023 # fraction
      n_structures: 256963 # count
      analysis_file: models/allegro/Allegro-OAM-L-0.1/Allegro-OAM-L-0.1-2025-08-26-wbm-IS2RE-GOQN-symprec=1e-5-moyo=0.4.4.csv.gz
      analysis_file_url: https://figshare.com/files/57731047
  discovery:
    pred_file: models/allegro/Allegro-OAM-L-0.1/Allegro-OAM-L-0.1-2025-08-26-wbm-IS2RE.csv.gz
    pred_file_url: https://figshare.com/files/57574801
    pred_col: e_form_per_atom_nequip # same for NequIP/Allegro
    full_test_set:
      F1: 0.873 # fraction
      DAF: 4.876 # dimensionless
      Precision: 0.837 # fraction
      Recall: 0.912 # fraction
      Accuracy: 0.954 # fraction
      TPR: 0.912 # fraction
      FPR: 0.037 # fraction
      TNR: 0.963 # fraction
      FNR: 0.088 # fraction
      TP: 40220.0 # count
      FP: 7854.0 # count
      TN: 205017.0 # count
      FN: 3872.0 # count
      MAE: 0.021 # eV/atom
      RMSE: 0.067 # eV/atom
      R2: 0.861 # dimensionless
      missing_preds: 2 # count
    unique_prototypes:
      F1: 0.895 # fraction
      DAF: 5.674 # dimensionless
      Precision: 0.867 # fraction
      Recall: 0.923 # fraction
      Accuracy: 0.966 # fraction
      TPR: 0.923 # fraction
      FPR: 0.026 # fraction
      TNR: 0.974 # fraction
      FNR: 0.077 # fraction
      TP: 30817.0 # count
      FP: 4709.0 # count
      TN: 177405.0 # count
      FN: 2557.0 # count
      MAE: 0.022 # eV/atom
      RMSE: 0.067 # eV/atom
      R2: 0.868 # dimensionless
      missing_preds: 0 # count
    most_stable_10k:
      F1: 0.987 # fraction
      DAF: 6.371 # dimensionless
      Precision: 0.974 # fraction
      Recall: 1.0 # fraction
      Accuracy: 0.974 # fraction
      TPR: 1.0 # fraction
      FPR: 1.0 # fraction
      TNR: 0.0 # fraction
      FNR: 0.0 # fraction
      TP: 9739.0 # count
      FP: 261.0 # count
      TN: 0.0 # count
      FN: 0.0 # count
      MAE: 0.018 # eV/atom
      RMSE: 0.065 # eV/atom
      R2: 0.908 # dimensionless
      missing_preds: 0 # count
