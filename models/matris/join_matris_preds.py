"""Concatenate MatRIS results from multiple data files generated by slurm job array into
single file."""

# %%
import os
from glob import glob

import pandas as pd
import pymatviz as pmv
from pymatviz.enums import Key
from tqdm import tqdm

from matbench_discovery.data import as_dict_handler
from matbench_discovery.energy import get_e_form_per_atom
from matbench_discovery.enums import MbdKey, Model, Task
from matbench_discovery.preds.discovery import df_preds

module_dir = os.path.dirname(__file__)


# %%
task_type = Task.IS2RE
date = "2025-03-12"
glob_pattern = f"{Model.matris_v050_mptrj}/{date}-wbm-{task_type}*/*.json.gz"
file_paths = sorted(glob(f"{module_dir}/{glob_pattern}"))
print(f"Found {len(file_paths):,} files for {glob_pattern = }")
dfs: dict[str, pd.DataFrame] = {}


# %%
failed = {}
for file_path in tqdm(file_paths):
    if file_path in dfs:
        continue
    try:
        df_i = pd.read_json(file_path).set_index(Key.mat_id)
    except Exception as exc:
        failed[file_path] = str(exc)
        continue
    # drop trajectory to save memory
    dfs[file_path] = df_i.drop(columns="matris_mp_trajectory", errors="ignore")


err_counts = pd.Series(failed).value_counts()
print(f"{err_counts=}")

df_matris = pd.concat(dfs.values()).round(4)


# %% compute corrected formation energies
e_pred_col = "matris_mp_energy"
e_form_matris_col = f"e_form_per_atom_{e_pred_col.split('_energy')[0]}"
df_matris[Key.formula] = df_preds[Key.formula]
df_matris[e_form_matris_col] = [
    get_e_form_per_atom(dict(energy=ene, composition=formula))
    for formula, ene in tqdm(
        df_matris.set_index(Key.formula)[e_pred_col].items(), total=len(df_matris)
    )
]
df_preds[e_form_matris_col] = df_matris[e_form_matris_col]


# %%
ax = pmv.density_scatter_plotly(
    df=df_preds,
    x=MbdKey.e_form_dft,
    y=e_form_matris_col,
    template="pymatviz_white",
)

# ax.write_html(f"matris_v050.html")


# %%
out_path = file_paths[0].rsplit("/", 1)[0]
df_matris = df_matris.round(4)
df_matris.select_dtypes("number").to_csv(f"{out_path}.csv.gz")
df_matris.reset_index().to_json(f"{out_path}.json.gz", default_handler=as_dict_handler)
