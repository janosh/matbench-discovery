model_name: eqV2 S DeNS
model_key: eqV2-s-dens-mp
model_version: v2024.10.18
matbench_discovery_version: 1.3.1
date_added: "2024-10-18"
date_published: "2024-10-18"
authors:
  - name: Luis Barroso-Luque
    affiliation: FAIR Meta
    email: lbluque@meta.com
    orcid: https://orcid.org/0000-0002-6453-9545
    github: https://github.com/lbluque
    corresponding: true
  - name: Muhammed Shuaibi
    affiliation: FAIR Meta
  - name: Xiang Fu
    affiliation: FAIR Meta
  - name: Brandon M. Wood
    affiliation: FAIR Meta
  - name: Misko Dzamba
    affiliation: FAIR Meta
  - name: Meng Gao
    affiliation: FAIR Meta
  - name: Ammar Rizvi
    affiliation: FAIR Meta
  - name: C.~Lawrence Zitnick
    affiliation: FAIR Meta
  - name: Zachary W. Ulissi
    affiliation: FAIR Meta
    email: zulissi@meta.com
    orcid: https://orcid.org/0000-0002-9401-4918
    corresponding: true

repo: https://github.com/FAIR-Chem/fairchem
doi: https://doi.org/10.48550/arXiv.2410.12771
paper: https://arxiv.org/abs/2410.12771
url: https://huggingface.co/fairchem/OMAT24
pypi: https://pypi.org/project/fairchem-core
pr_url: https://github.com/janosh/matbench-discovery/pull/146

requirements:
  fairchem-core: 1.2.1

openness: OSOD
trained_for_benchmark: true
train_task: S2EFS
test_task: IS2RE-SR
targets: EFS_D
model_type: UIP
model_params: 31_207_434 # 31M
n_estimators: 1

training_set: [MPtrj]

hyperparams:
  max_force: 0.02
  max_steps: 500
  ase_optimizer: FIRE
  loss: MAE
  loss_weights:
    energy: 20
    forces: 20
    stress: 5
    dens: 10
  dens_probability: 0.5
  noise_std: 0.1
  optimizer: AdamW
  learning_rate_schedule: Cosine
  warmup_epochs: 0.1
  warmup_factor: 0.2
  max_learning_rate: 0.0002
  min_learning_rate_factor: 0.01
  grad_clip_threshold: 100
  ema_decay: 0.999
  weight_decay: 0.001
  dropout_rate: 0.1
  stochastic_depth: 0.1
  batch_size: 512
  epochs: 150

notes:
  Description: |
    EquiformerV2 is an equivariant transformer that uses graph attention, attention re-normalization, and separable S^2 activations and layer normalization.
    Denoising Non-Equilibrium Structures (DeNS) uses a denoising generalized to structures with non-zero forces by encoding forces to obtain a well-posed denoising problem.
  Training: |
    Training was done from scratch using MPTrj only and a 50% probability for denoising training structures.

metrics:
  phonons:
    kappa_103:
      κ_SRME: 1.676 # eqV2 S without denoising (no DeNS) achieves slightly worse κ_SRME=1.772
      pred_file: models/eqV2/eqV2-s-dens-mp/2024-11-08-kappa-103-FIRE-dist=0.01-fmax=1e-4-symprec=1e-5.json.gz
      pred_file_url: https://figshare.com/ndownloader/files/52151558
  geo_opt:
    pred_file: models/eqV2/eqV2-s-dens-mp/2024-10-18-wbm-geo-opt.json.gz
    pred_file_url: https://figshare.com/ndownloader/files/52062392
    struct_col: eqV2-31M-dens-MP-p5_structure
    symprec=1e-5:
      rmsd: 0.0138 # Å
      n_sym_ops_mae: 10.0558 # unitless
      symmetry_decrease: 0.8611 # fraction
      symmetry_match: 0.1382 # fraction
      symmetry_increase: 0.0005 # fraction
      n_structures: 256614 # count
      analysis_file: models/eqV2/eqV2-s-dens-mp/2024-10-18-wbm-geo-opt-symprec=1e-5.csv.gz
      analysis_file_url: https://figshare.com/ndownloader/files/52062569
    symprec=1e-2:
      rmsd: 0.0138 # Å
      n_sym_ops_mae: 3.9922 # unitless
      symmetry_decrease: 0.4074 # fraction
      symmetry_match: 0.5027 # fraction
      symmetry_increase: 0.0631 # fraction
      n_structures: 256614 # count
      analysis_file: models/eqV2/eqV2-s-dens-mp/2024-10-18-wbm-geo-opt-symprec=1e-2.csv.gz
      analysis_file_url: https://figshare.com/ndownloader/files/52062578
  discovery:
    pred_file: models/eqV2/eqV2-s-dens-mp/2024-10-18-wbm-IS2RE.csv.gz
    pred_file_url: https://figshare.com/ndownloader/files/52057568
    pred_col: e_form_per_atom_eqV2-31M-dens-MP-p5
    full_test_set:
      F1: 0.798 # fraction
      DAF: 4.362 # dimensionless
      Precision: 0.748 # fraction
      Recall: 0.855 # fraction
      Accuracy: 0.927 # fraction
      TPR: 0.855 # fraction
      FPR: 0.059 # fraction
      TNR: 0.941 # fraction
      FNR: 0.145 # fraction
      TP: 37687.0 # count
      FP: 12665.0 # count
      TN: 200206.0 # count
      FN: 6405.0 # count
      MAE: 0.035 # eV/atom
      RMSE: 0.084 # eV/atom
      R2: 0.785 # dimensionless
      missing_preds: 351 # count
      missing_percent: 0.14% # fraction
    most_stable_10k:
      F1: 0.983 # fraction
      DAF: 6.326 # dimensionless
      Precision: 0.967 # fraction
      Recall: 1.0 # fraction
      Accuracy: 0.967 # fraction
      TPR: 1.0 # fraction
      FPR: 1.0 # fraction
      TNR: 0.0 # fraction
      FNR: 0.0 # fraction
      TP: 9670.0 # count
      FP: 330.0 # count
      TN: 0.0 # count
      FN: 0.0 # count
      MAE: 0.031 # eV/atom
      RMSE: 0.091 # eV/atom
      R2: 0.823 # dimensionless
      missing_preds: 0 # count
      missing_percent: 0.00% # fraction
    unique_prototypes:
      F1: 0.815 # fraction
      DAF: 5.042 # dimensionless
      Precision: 0.771 # fraction
      Recall: 0.864 # fraction
      Accuracy: 0.941 # fraction
      TPR: 0.864 # fraction
      FPR: 0.047 # fraction
      TNR: 0.953 # fraction
      FNR: 0.136 # fraction
      TP: 28842.0 # count
      FP: 8576.0 # count
      TN: 173538.0 # count
      FN: 4532.0 # count
      MAE: 0.036 # eV/atom
      RMSE: 0.085 # eV/atom
      R2: 0.788 # dimensionless
      missing_preds: 309 # count
      missing_percent: 0.14% # fraction
