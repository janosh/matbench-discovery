model_name: eqV2 S DeNS
model_version: v2024.10.18
matbench_discovery_version: 1.3.1
date_added: "2024-10-18"
date_published: "2024-10-18"
authors:
  - name: Luis Barroso-Luque
    affiliation: FAIR Meta
    email: lbluque@meta.com
    orcid: https://orcid.org/0000-0002-6453-9545
    github: https://github.com/lbluque
    corresponding: true
  - name: Muhammed Shuaibi
    affiliation: FAIR Meta
  - name: Xiang Fu
    affiliation: FAIR Meta
  - name: Brandon M. Wood
    affiliation: FAIR Meta
  - name: Misko Dzamba
    affiliation: FAIR Meta
  - name: Meng Gao
    affiliation: FAIR Meta
  - name: Ammar Rizvi
    affiliation: FAIR Meta
  - name: C.~Lawrence Zitnick
    affiliation: FAIR Meta
  - name: Zachary W. Ulissi
    affiliation: FAIR Meta
    email: zulissi@meta.com
    orcid: https://orcid.org/0000-0002-9401-4918
    corresponding: true

repo: https://github.com/FAIR-Chem/fairchem
doi: https://doi.org/10.48550/arXiv.2410.12771
paper: https://arxiv.org/abs/2410.12771
url: https://huggingface.co/fairchem/OMAT24
pypi: https://pypi.org/project/fairchem-core

requirements:
  fairchem-core: 1.2.1

openness: OSOD
trained_for_benchmark: true
train_task: S2EFS
test_task: IS2RE-SR
targets: EFS_D
model_type: UIP
model_params: 31_207_434
n_estimators: 1

training_set: [MPtrj]

hyperparams:
  max_force: 0.02
  max_steps: 500
  ase_optimizer: FIRE
  loss: MAE
  loss_weights:
    energy: 20
    forces: 20
    stress: 5
    dens: 10
  dens_probability: 0.5
  noise_std: 0.1
  optimizer: AdamW
  learning_rate_schedule: Cosine
  warmup_epochs: 0.1
  warmup_factor: 0.2
  max_learning_rate: 0.0002
  min_learning_rate_factor: 0.01
  grad_clip_threshold: 100
  ema_decay: 0.999
  weight_decay: 0.001
  dropout_rate: 0.1
  stochastic_depth: 0.1
  batch_size: 512
  epochs: 150
  # train_config_url: #TODO add URL

notes:
  Description: |
    EquiformerV2 is an equivariant transformer that uses graph attention, attention re-normalization, and separable S^2 activations and layer normalization.
    Denoising Non-Equilibrium Structures (DeNS) uses a denoising generalized to structures with non-zero forces by encoding forces to obtain a well-posed denoising problem.
  Training: |
    Training was done from scratch using MPTrj only and a 50% probability for denoising training structures.

metrics:
  phonons:
    κ_SRME: 1.665 # eqV2 S without denoising (no DeNS) achieves slightly worse κ_SRME=1.772
  geo_opt:
    pred_file: null # authors will share model-relaxed structures soon
    pred_col: null
  discovery:
    pred_file: models/eqV2/eqV2-s-dens-mp.csv.gz
    pred_col: e_form_per_atom_eqV2-31M-dens-MP-p5
    full_test_set:
      F1: 0.798
      DAF: 4.362
      Precision: 0.748
      Recall: 0.855
      Accuracy: 0.927
      TPR: 0.855
      FPR: 0.059
      TNR: 0.941
      FNR: 0.145
      TP: 37687.0
      FP: 12665.0
      TN: 200206.0
      FN: 6405.0
      MAE: 0.035
      RMSE: 0.084
      R2: 0.785
      missing_preds: 351
      missing_percent: 0.14%
    most_stable_10k:
      F1: 0.983
      DAF: 6.326
      Precision: 0.967
      Recall: 1.0
      Accuracy: 0.967
      TPR: 1.0
      FPR: 1.0
      TNR: 0.0
      FNR: 0.0
      TP: 9670.0
      FP: 330.0
      TN: 0.0
      FN: 0.0
      MAE: 0.031
      RMSE: 0.091
      R2: 0.823
      missing_preds: 0
      missing_percent: 0.00%
    unique_prototypes:
      F1: 0.815
      DAF: 5.042
      Precision: 0.771
      Recall: 0.864
      Accuracy: 0.941
      TPR: 0.864
      FPR: 0.047
      TNR: 0.953
      FNR: 0.136
      TP: 28842.0
      FP: 8576.0
      TN: 173538.0
      FN: 4532.0
      MAE: 0.036
      RMSE: 0.085
      R2: 0.788
      missing_preds: 309
      missing_percent: 0.14%
