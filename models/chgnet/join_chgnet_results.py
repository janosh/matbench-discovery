"""Concatenate chgnet results from multiple data files generated by slurm job array
into single file.
"""


# %%
from __future__ import annotations

import os
import warnings
from glob import glob

import pandas as pd
from megnet.utils.models import load_model
from pymatgen.core import Structure
from pymatgen.entries.compatibility import MaterialsProject2020Compatibility
from pymatgen.entries.computed_entries import ComputedStructureEntry
from pymatviz import density_scatter
from tqdm import tqdm

from matbench_discovery import today
from matbench_discovery.data import DATA_FILES, as_dict_handler
from matbench_discovery.energy import get_e_form_per_atom
from matbench_discovery.preds import df_wbm as df_summary
from matbench_discovery.preds import e_form_col

__author__ = "Janosh Riebesell"
__date__ = "2023-03-01"

warnings.filterwarnings(action="ignore", category=UserWarning, module="pymatgen")


# %%
module_dir = os.path.dirname(__file__)
task_type = "IS2RE"
date = "2023-03-04"
glob_pattern = f"{date}-chgnet-wbm-{task_type}*/*.json.gz"
file_paths = sorted(glob(f"{module_dir}/{glob_pattern}"))
print(f"Found {len(file_paths):,} files for {glob_pattern = }")

dfs: dict[str, pd.DataFrame] = {}


# %%
for file_path in tqdm(file_paths):
    if file_path in dfs:
        continue
    df = pd.read_json(file_path).set_index("material_id")
    # drop trajectory to save memory
    dfs[file_path] = df.drop(columns="chgnet_trajectory")


# %%
df_chgnet = pd.concat(dfs.values()).round(4)


# %%
df_wbm = pd.read_json(DATA_FILES.wbm_computed_structure_entries).set_index(
    "material_id"
)

df_wbm["cse"] = [
    ComputedStructureEntry.from_dict(x) for x in tqdm(df_wbm.computed_structure_entry)
]


# %% transfer chgnet energies and relaxed structures WBM CSEs
cse: ComputedStructureEntry
for row in tqdm(df_chgnet.itertuples(), total=len(df_chgnet)):
    mat_id, struct_dict, chgnet_energy, *_ = row
    chgnet_struct = Structure.from_dict(struct_dict)
    cse = df_wbm.loc[mat_id, "cse"]
    cse._energy = chgnet_energy  # cse._energy is the uncorrected energy
    cse._structure = chgnet_struct
    df_chgnet.loc[mat_id, "cse"] = cse


# %%
df_chgnet["e_form_per_atom_chgnet_uncorrected"] = [
    get_e_form_per_atom(cse) for cse in tqdm(df_chgnet.cse)
]


# %% apply energy corrections
out = MaterialsProject2020Compatibility().process_entries(
    df_chgnet.cse, verbose=True, clean=True
)
assert len(out) == len(df_chgnet)


# %% compute corrected formation energies
df_chgnet["e_form_per_atom_chgnet"] = [
    get_e_form_per_atom(cse) for cse in tqdm(df_chgnet.cse)
]

df_chgnet[e_form_col] = df_summary[e_form_col]


# %%
ax = density_scatter(
    df=df_chgnet, x="e_form_per_atom_chgnet", y="e_form_per_atom_chgnet_uncorrected"
)
ax = density_scatter(df=df_chgnet, x="e_form_per_atom_chgnet", y=e_form_col)


# %% load 2019 MEGNet formation energy model
megnet_mp_e_form = load_model("Eform_MP_2019")
megnet_e_form_preds: dict[str, float] = {}


# %% predict formation energies on chgnet relaxed structure with MEGNet
for material_id, cse in tqdm(df_wbm.cse.items(), total=len(df_wbm)):
    if material_id in megnet_e_form_preds:
        continue
    try:
        struct = cse.structure
        [e_form_per_atom] = megnet_mp_e_form.predict_structure(struct)
        megnet_e_form_preds[material_id] = e_form_per_atom
    except Exception as exc:
        print(f"Failed to predict {material_id=}: {exc}")

df_chgnet["e_form_per_atom_chgnet_megnet"] = pd.Series(megnet_e_form_preds)

assert (
    n_isna := df_chgnet.e_form_per_atom_chgnet_megnet.isna().sum()
) < 10, f"{n_isna=}, expected 7 or similar"


# %%
ax = density_scatter(
    df=df_chgnet, x="e_form_per_atom_chgnet_megnet", y="e_form_per_atom_chgnet"
)


# %%
out_path = f"{module_dir}/{today}-chgnet-wbm-{task_type}.json.gz"
df_chgnet = df_chgnet.round(4)
df_chgnet.reset_index().to_json(out_path, default_handler=as_dict_handler)

df_chgnet.select_dtypes("number").to_csv(out_path.replace(".json.gz", ".csv"))

# in_path = f"{module_dir}/2022-10-31-chgnet-wbm-IS2RE.json.gz"
# df_chgnet_csv = pd.read_csv(in_path.replace(".json.gz", ".csv"))
# df_chgnet = pd.read_json(in_path).set_index("material_id")
