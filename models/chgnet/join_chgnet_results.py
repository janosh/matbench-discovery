"""Concatenate chgnet results from multiple data files generated by slurm job array
into single file.
"""


# %%
from __future__ import annotations

import os
import warnings
from glob import glob

import pandas as pd
from megnet.utils.models import load_model
from pymatgen.core import Structure
from pymatgen.entries.compatibility import MaterialsProject2020Compatibility
from pymatgen.entries.computed_entries import ComputedStructureEntry
from pymatviz import density_scatter
from tqdm import tqdm

from matbench_discovery import today
from matbench_discovery.data import DATA_FILES, as_dict_handler
from matbench_discovery.energy import get_e_form_per_atom
from matbench_discovery.preds import df_wbm, e_form_col

__author__ = "Janosh Riebesell"
__date__ = "2023-03-01"

warnings.filterwarnings(action="ignore", category=UserWarning, module="pymatgen")


# %%
module_dir = os.path.dirname(__file__)
task_type = "IS2RE"
date = "2023-03-04"
glob_pattern = f"{date}-chgnet-wbm-{task_type}*/*.json.gz"
file_paths = sorted(glob(f"{module_dir}/{glob_pattern}"))
print(f"Found {len(file_paths):,} files for {glob_pattern = }")

dfs: dict[str, pd.DataFrame] = {}


# %%
for file_path in tqdm(file_paths):
    if file_path in dfs:
        continue
    df = pd.read_json(file_path).set_index("material_id")
    # drop trajectory to save memory
    dfs[file_path] = df.drop(columns="chgnet_trajectory")


# %%
df_chgnet = pd.concat(dfs.values()).round(4)


# %%
df_cse = pd.read_json(DATA_FILES.wbm_computed_structure_entries).set_index(
    "material_id"
)

df_cse["cse"] = [
    ComputedStructureEntry.from_dict(x) for x in tqdm(df_cse.computed_structure_entry)
]


# %% transfer CHGNet energies and relaxed structures WBM CSEs since MP2020 energy
# corrections applied below are structure-dependent (for oxides and sulfides)
cse: ComputedStructureEntry
for row in tqdm(df_chgnet.itertuples(), total=len(df_chgnet)):
    mat_id, struct_dict, chgnet_energy, *_ = row
    chgnet_struct = Structure.from_dict(struct_dict)
    cse = df_cse.loc[mat_id, "cse"]
    cse._energy = chgnet_energy  # cse._energy is the uncorrected energy
    cse._structure = chgnet_struct
    df_chgnet.loc[mat_id, "cse"] = cse


# %% apply energy corrections to CSEs with CHGNet
out = MaterialsProject2020Compatibility().process_entries(
    df_chgnet.cse, verbose=True, clean=True
)
assert len(out) == len(df_chgnet)


# %% compute corrected formation energies
e_form_chgnet_col = "e_form_per_atom_chgnet"
df_chgnet[e_form_chgnet_col] = [get_e_form_per_atom(cse) for cse in tqdm(df_chgnet.cse)]


# %%
ax = density_scatter(x=df_wbm[e_form_col], y=df_chgnet[e_form_chgnet_col])


# %% load 2019 MEGNet formation energy model
megnet_mp_e_form = load_model("Eform_MP_2019")
megnet_e_form_preds: dict[str, float] = {}


# %% predict formation energies on chgnet relaxed structure with MEGNet
for material_id, cse in tqdm(df_cse.cse.items(), total=len(df_cse)):
    if material_id in megnet_e_form_preds:
        continue
    try:
        struct = cse.structure
        [e_form_per_atom] = megnet_mp_e_form.predict_structure(struct)
        megnet_e_form_preds[material_id] = e_form_per_atom
    except Exception as exc:
        print(f"Failed to predict {material_id=}: {exc}")

e_form_megnet_col = "e_form_per_atom_chgnet_megnet"
# remove legacy MP corrections that MEGNet was trained on and apply newer MP2020
# corrections instead
df_chgnet[e_form_megnet_col] = (
    pd.Series(megnet_e_form_preds)
    - df_wbm.e_correction_per_atom_mp_legacy
    + df_wbm.e_correction_per_atom_mp2020
)

assert (
    n_isna := df_chgnet.e_form_per_atom_chgnet_megnet.isna().sum()
) < 10, f"{n_isna=}, expected 7 or similar"


# %%
ax = density_scatter(df=df_chgnet, x=e_form_chgnet_col, y=e_form_megnet_col)
ax = density_scatter(df=df_chgnet, x=e_form_col, y=e_form_megnet_col)


# %%
out_path = f"{module_dir}/{today}-chgnet-wbm-{task_type}.json.gz"
df_chgnet = df_chgnet.round(4)
df_chgnet.reset_index().to_json(out_path, default_handler=as_dict_handler)

df_chgnet.select_dtypes("number").to_csv(out_path.replace(".json.gz", ".csv"))

# in_path = f"{module_dir}/2022-10-31-chgnet-wbm-IS2RE.json.gz"
# df_chgnet_csv = pd.read_csv(in_path.replace(".json.gz", ".csv"))
# df_chgnet = pd.read_json(in_path).set_index("material_id")
