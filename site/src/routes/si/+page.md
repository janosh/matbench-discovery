<script lang="ts">
  import RunTimeBars from '$figs/model-run-times-bar.svelte'
  import RocModels from '$figs/roc-models.svelte'
  import { browser } from '$app/environment'
  import MPRefEnergies from '$figs/mp-elemental-ref-energies.svelte'
  import WrenformerRollingMaeBatches from '$figs/wrenformer-rolling-mae-vs-hull-dist-wbm-batches.svelte'
  import M3gnetRollingMaeBatches from '$figs/m3gnet-rolling-mae-vs-hull-dist-wbm-batches.svelte'
  import MegnetRollingMaeBatches from '$figs/megnet-rolling-mae-vs-hull-dist-wbm-batches.svelte'
  import HistClfPredHullDistModels from '$figs/hist-clf-pred-hull-dist-models.svelte'
  import { onMount } from 'svelte'

  let mounted = false
  onMount(() => (mounted = true))
</script>

# Supplementary Information

## ROC Curves

{#if mounted}
<RocModels />
{/if}

> @label:fig:roc-models Receiver operating characteristic (ROC) curve for each model. TPR/FPR = true/false positive rate. FPR on the $x$-axis is the fraction of unstable structures classified as stable. TPR on the $y$-axis is the fraction of stable structures classified as stable. Points are colored by stability threshold $t$ which sweeps from $-0.4 \ \frac{\text{eV}}{\text{atom}} \leq t \leq 0.4 \ \frac{\text{eV}}{\text{atom}}$ above the hull. A material is classified as stable if the predicted E<sub>above hull</sub> lies below the stability threshold. Since all models predict E<sub>form</sub> (and M3GNet predicted energies are converted to formation energy before stability classification), they are insensitive to changes in the threshold $t$. M3GNet wins in area under curve (AUC) with 0.87, coming in 34% higher than the worst model Voronoi Random Forest. The diagonal 'No skill' line shows performance of a dummy model that randomly ranks material stability.

## Model Run Times

{#if mounted}
<RunTimeBars style="margin: 1em;" />
{/if}

> @label:fig:model-run-times-pie Creating this benchmark (excluding debugging runs) used a total of 3297 hours of compute time (mix of CPU and GPU, mostly CPU). Notably, the vast majority of that was used in the Bayesian optimization step of the BOWSR+MEGnet model.

## Formation Energy MAE = Hull Distance MAE

To avoid potential confusion for people reading the code, we may in places calculate the formation energy MAE and report it as the MAE for the energy above the convex hull prediction. The former is more easily calculated but the two quantities are the same. The formation energy of a material is the difference in energy between a material and its constituent elements in their standard states. The distance to the convex hull is defined as the difference between a material's formation energy and the minimum formation energy of all possible stable materials made from the same elements. Since the formation energy of a material is used to calculate the distance to the convex hull, the error of a formation energy prediction directly determines the error in the distance to the convex hull prediction.

## MP Elemental Reference Energies

{#if mounted}
<MPRefEnergies />
{/if}

> @label:fig:mp-elemental-reference-energies WBM formation energies were calculated w.r.t. these Materials Project elemental reference energies ([queried on 2022-09-19](https://github.com/janosh/matbench-discovery/blob/main/data/mp/2022-09-19-mp-elemental-reference-entries.json)). Marker size indicates the number of atoms in the reference structure. Hover points for details.

## Classification Histograms using Model-Predicted Energies

{#if mounted}
<HistClfPredHullDistModels />
{/if}

> @label:fig:hist-clf-pred-hull-dist-models Similar to [this figure](/paper#fig:hist-clf-true-hull-dist-models), this histogram shows model stability classification as a function of the distance to the convex hull. The difference here being the $x$ axis showing model-predicted rather than DFT ground-truth distance to the convex hull. Intuitively, it shows hof often models misclassify as a function of how far they think a material is from the convex hull.

## WBM Batch Robustness as a Measure of Extrapolation Prowess

The following 3 plots show how the rolling MAE as a function of distance to the convex hull changes with elemental substitution count. As a reminder, the WBM test set was generated in 5 batches, each applying another element replacement according to ISCD-mined chemical similarity scores to MP source structures and/or the new stable crystals generated by the previous round. Naively, you'd expect model performance to degrade with increasing batch count since the repeated elemental substitutions should on average 'diffuse' deeper into uncharted regions of material space, requiring the model to extrapolate more and more.

<M3gnetRollingMaeBatches />

> @label:fig:m3gnet-rolling-mae-vs-hull-dist-wbm-batches M3GNet shows robust performance across all batches with only minor error increase for later batches.

<WrenformerRollingMaeBatches />

> @label:fig:wrenformer-rolling-mae-vs-hull-dist-wbm-batches By contrast, Wrenformer shows a more pronounced increase in MAE with batch count. This suggests that perhaps training on composition, spacegroup and Wyckoff positions alone is insufficient for learning a robust map of the PES beyond the regions of materials space covered by the training data.

<MegnetRollingMaeBatches />

> @label:fig:megnet-rolling-mae-vs-hull-dist-wbm-batches MEGNet proves to be the exception to the naive expectation of increasing error for later WBM batches. Batch 1 oddly accrues the highest error, esp. for unstable materials (right half of the plot). The MAE lines are also noticeably more erratic than those of M3GNet.
